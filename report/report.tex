\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage[numbers]{natbib}
\usepackage{amsmath}

%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09

\begin{document}

\title{Applying Deep Learning to predict Bracketology for NCAA's March Madness
\author{Loyzer, Mark \texttt{loyzer@cs.toronto.edu}}
\affil{Department of Computer Science
University of Toronto
Toronto, Ontario, Canada}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\maketitle

\section{Introduction}
This project focuses on predicting the bracketology for NCAA's March Madness tournament.  We leverage the dataset from Kaggle's online competition \citep{kagglecompetition}.  Parsing the data and constructing relevant features is one of the main efforts in this project as all the data provided is.  The data comes in two forms: detailed and compact, where compact is a subset of the features in detailed.  The ground-truth labels are stored as another feature in the data and so can easily be obtained.  For each example, the a subset of the features can remain to comprise the feature vector; however, additional features are added and discussed in section~\ref{sec:data-features}.


The task of predicting the all-but-first bracketology is complex: the first round (initial seedings are provided to you, and you must predict the winners of the subsequent rounds until only one team remains and is crowned champion.  For the second round there will be $2^{32}$ possible outcomes since there are 64 teams in the first round.  Then $2^{16}$, \dots, $2$ possibilities for each subsequent round.  Since each round depends on the results of the previous there are $\prod_{i=1}^{\log(32)} 2^{2^{i}} = \prod_{i=1}^{\log(32)} 4^{i} = 4^{\Sigma_{i=1}^{\log(32)} i} = 4^{15}$ possible outcomes.   The odds of predicting a perfect bracket are, needless to say; however, the exact probability in this case would be $\frac{1}{4^{15}} \approx 9.3132257e^{-10}$.  So, let the odds forever be in our favour.


To generate competitive performance, we considered a variety of deep learning models which exploit different feature representations.  We attempt both the detailed and compact feature sets as well as additional hand-crafted and learned features as well.  Since the application of deep learning to predicting tournament bracketology is new (we could not find any articles to people who have tried this before) we experiment with a few different deep learning models to see which performs/generalizes best.  The models are described in section~\ref{sec:models}.  We describe the setup, performance, results, and summarize the investigation for each of the techniques.


\section{Background and Related Work}
\label{sec:background-related-work}

\textbf{Brief overview of previous models.}  Many of the current and past contestants in Kaggle's competition \citep{kagglecompetition} use some very primitive models like linear or logistic regression.  While others have used statistical measures to quantify (or rank) how good a team is.  Some of these measures are by a Winning Index but the more common approach was to use ELO \citep{elo} and so the winner was the team that had the better score using a direct comparison between the two teams.  Some of the early attempts were to compute these metrics or even an offensive and defensive rating (on the same scale) and compute a linear combination of the two team's offensive and defensive ranking and predict the team that matches up best against each other.  Some ensemble methods were tried using Adaboost and decision tree stumps with some succes.  Starting in about 2015 some people started using neural networks, though the techniques I saw were player based models instead of team where players are categorized based on the role positions in basketball, and the final game roster is based on the players that played the most during the season.

\textbf{Investigating the success of past winners.}  The winner in 2013 used represented a team as a vector of the 5 players on a court at any given time.  Each position would be given a real number which indicated how good that team was at that position for both offense and defense.  Predicted scored were computed by taking the dot product between oppossing vectors (offsense with defense) and the predicted winning team would be the one with the larger predicted score.   The optimization/learning was in the determining the values for the offensive and defensive vectors.  A squared error cost function was used with a convex optimization algorithm.  The winners in 2014 used a margin-of-victory model which predicted the difference in score between the two teams and chose the winning team with the positive margin.  Their model was updated as games completed during the tournament which helped account for any inconsistencies or potentialy exceptional situations that could be inferred from score (for example, a team's best player being injurred and out after the first two quarters in a round 1 game).  In 2015 the winner took a bayesian approach incorporating his experience as a sports analyst as the priors in a Bayesian classifier \citep{kaggle2015winner}.  In 2016, the winners initially tried using Adaboost (which is a way to combine multiple weak classifiers into one final classifier) but received poor results \citep{kaggle2016winner} and decided to opt for a logistic regression classifier with random forests (which is also an ensemble learning method).  Random forests combine several decision tree classifiers to predict the target usually using a weighted mean over all decision trees.

\textbf{Survey of models for game prediction.}  The dissertation by \citet{cao2012sports} investigates using a simple logistic classifier, neural networks, support vector machines, and naive Bayes with performance being in that order.  They also consider an engineered feature of the past 10 home/road games but distinguish between a home and away game.  They also consider external features like game schedule (home vs away game is considered an external feature as well).

\textbf{Traditional measures are inadequate.}  The paper by \citet{bashuk2012using} disqualify using traditional ranking methods such as Average Scoring Margin (ASM) and Ratings percentage Index (RPI) due to their myopic view of considering only scores in past games to predict future game outcomes.  \citet{bashuk2012using} investigate cumulative win probabilities over the duration of a game to measure both the team and each player's individual performance.  They then use 5 years of past game data to generate a ``Win Probability Index" (WPI) metric which outperforms ASM and RPI in predicting NCAA basketball games.  This paper shows the advantages of using indirect but correlated features (with respect to winning) and invokes the question as to which is more imporant: less data with more (but hopefully relevant) features or more data with only a subset of the features.  This will be evaluated as the compact and detailed datasets provided begin with


\section{Data}
\label{sec:data}

\subsection{Game Outcomes}
\label{sec:data-winner}

In this task we take on the challenge of predicting the winner between two teams in a game.  In its most general case you can consider the training input to be of the form: [[vector for team1], [vector for team2], [vector of comparative stats]], and so there is some natural \textit{symmetry} within each training example.  Namely we could have given the input as [[vector for team2], [vector for team1], [vector of comparative stats]] as well and the target output would be either be identical or reflexive depending on what the output layer represents, but ultimately the target output would refelect which team won.  Due to this symmetry we actually do create both training examples during the data-collection process.  This doubles our data size and allows the computational models to be more robust in predicting games where we won't be necessarily given some predefined structure (like alphabetical ordering by team name as an example).

\subsubsection{Setup}
\label{sec:data-winner-setup}

There are two data sets we explored.  The compact and detailed data sets provided by Kaggle \citep{kagglecompetition}.  Each file and their description is below.  Before evaluating the models one thing to note is that the compact vs detailed vary in the number of data examples each have.  Compact results have been aggregated from 1985 to present, while detailed results have only been aggregated from 2003 to present.  This leaves an interesting question as to is more data with fewer features a better predictor than less data but more features.  Clearly there is some tradeoff (maybe some of the detailed features are noise and not relevant predictors but without more data the model isn't able to learn this).  Regardless.

The results datasets (RegularSeasonCompactResults, RegularSeasonDetailedResults, TourneyCompactResults, and TourneyDetailedResutls) are used in the intuitive sense: they comprise the basis for the examples to train and evaluate the predictor model.  The daynum feature was used to actually merge the results into one dataset.  This was done because we also constructed two handcrafted features which we call the hot-streak and rival-streak.  The hot-streak is the win/loss for a team in the past X games, and the rival-streak is the win/loss for the past Y games for the current matchup.

RegularSeasonCompactResults
This file identifies the game-by-game results for 32 seasons of historical data, from 1985 to 2015. Each year, it includes all games played from daynum 0 through 132 (which by definition is "Selection Sunday," the day that tournament pairings are announced). Each row in the file represents a single game played.


RegularSeasonDetailedResults

This file is a more detailed set of game results, covering seasons 2003-2016. This includes team-level total statistics for each game (total field goals attempted, offensive rebounds, etc.) The column names should be self-explanatory to basketball fans (as above, ``w" or ``l" refers to the winning or losing team):


TourneyCompactResults
This file identifies the game-by-game NCAA tournament results for all seasons of historical data. The data is formatted exactly like the RegularSeasonCompactResults data. Note that these games also include the play-in games (which always occurred on day 134/135) for those years that had play-in games.

TourneyDetailedResults
This file contains the more detailed results for tournament games from 2003 onward.

Seasons
This file identifies the different seasons included in the historical data, along with certain season-level properties such as the season's year and day number, as well as how the regions are categorized for tournament play.

"season" - indicates the year in which the tournament was played
"dayzero" - tells you the date corresponding to daynum=0 during that season. All game dates have been aligned upon a common scale so that the championship game of the final tournament is on daynum=154. Working backward, the national semifinals are always on daynum=152, the "play-in" games are on days 134/135, Selection Sunday is on day 132, and so on. All game data includes the day number in order to make it easier to perform date calculations. If you really want to know the exact date a game was played on, you can combine the game's "daynum" with the season's "dayzero". For instance, since day zero during the 2011-2012 season was 10/31/2011, if we know that the earliest regular season games that year were played on daynum=7, they were therefore played on 11/07/2011.
"regionW/X/Y/Z" - by convention, the four regions in the final tournament are always named W, X, Y, and Z. Whichever region's name comes first alphabetically, that region will be Region W. And whichever Region plays against Region W in the national semifinals, that will be Region X. For the other two regions, whichever region's name comes first alphabetically, that region will be Region Y, and the other will be Region Z. This allows us to identify the regions and brackets in a standardized way in other files. For instance, during the 2012 tournament, the four regions were East, Midwest, South, and West. Being the first alphabetically, East becomes W. Since the East regional champion (Ohio State) played against the Midwest regional champion (Kansas) in the national semifinals, that makes Midwest be region X. For the other two (South and West), since South comes first alphabetically, that makes South Y and therefore West is Z. So for this season, the W/X/Y/Z are East,Midwest,South,West.


Teams
This file identifies the different college teams present in the dataset. Each team has a 4 digit id number.


\subsubsection{Features}
\label{sec:data-winner-features}

\subsubsubsection{Compact}
\label{sec:data-winner-features-compact}

\begin{description}
\item[\sout{season}] - this is the year of the associated entry in seasons.csv (the year in which the final tournament occurs)
\item[\sout{daynum}] - this integer always ranges from 0 to 132, and tells you what day the game was played on. It represents an offset from the ``dayzero" date in the ``seasons.csv" file. For example, the first game in the file was daynum=20. Combined with the fact from the ``season.csv" file that day zero was 10/29/1984, that means the first game was played 20 days later, or 11/18/1984. There are no teams that ever played more than one game on a given date, so you can use this fact if you need a unique key. In order to accomplish this uniqueness, we had to adjust one game's date. In March 2008, the SEC postseason tournament had to reschedule one game (Georgia-Kentucky) to a subsequent day, so Georgia had to actually play two games on the same day. In order to enforce this uniqueness, we moved the game date for the Georgia-Kentucky game back to its original date.
\item[wteam] this identifies the id number of the team that won the game, as listed in the ``teams.csv" file. No matter whether the game was won by the home team or visiting team, ``wteam" always identifies the winning team.
\item[wscore] this identifies the number of points scored by the winning team.
\item[lteam] this identifies the id number of the team that lost the game.
\item[lscore] this identifies the number of points scored by the losing team.
\item[\sout{numot}] this indicates the number of overtime periods in the game, an integer 0 or higher.
\item[\sout{wloc}] this identifies the ``location" of the winning team. If the winning team was the home team, this value will be ``H". If the winning team was the visiting team, this value will be ``A". If it was played on a neutral court, then this value will be ``N". Sometimes it is unclear whether the site should be considered neutral, since it is near one team's home court, or even on their court during a tournament, but for this determination we have simply used the Kenneth Massey data in its current state, where the ``@" sign is either listed with the winning team, the losing team, or neither team.
\end{description}




\subsubsubsection{Detailed}
\label{sec:data-winner-features-detailed}
The features in the detailed version of the data supersets the compact features.  The additional features (not included in compact) are the following where, again, w and l represent the statistic for the winning and losing team respectively and only the winning team statistics are shown for conciseness.

\begin{description}
\item[wfgm] field goals made
\item[wfga] field goals attempted
\item[wfgm3] three pointers made
\item[wfga3] three pointers attempted
\item[wftm] free throws made
\item[wfta] free throws attempted
\item[wor] offensive rebounds
\item[wdr] defensive rebounds
\item[wast] assists
\item[wto] turnovers
\item[wstl] steals
\item[wblk] blocks
\item[wpf] personal fouls
\end{description}


\subsubsubsection{Handcrafted Features}
\label{sec:data-winner-features-handcrafted}

There are two handcrafted features that we chose to incorporate into out feature-set.  We investigate the use of each of these employing a leave-one-out-like evaluation which investigated the affect of adding each of the features independent of each other.

The first handcrafted feature is called a team's ``hot streak".  Hot streak is the win/loss vector for a team in any given season.  To resolve issues where a team has not played many like (for example the first game of each season) we defined the win/loss vector to be a vector with values in the domain ${-1, 0, 1}$, where -1 represents loss, 0 represents not played, and 1 represents win.  This way for any unplayed games we can pad the hot streak vector with 0s and fill in the appropriate games with a -1 or 1.  So, for early season games this feature does not provide much information.

The second handcrafted feature is called a team's ``rival streak" with respect to another team (referred to as the rival). The win/loss vector also uses the domain ${-1, 0, 1}$ with the same meanings as in the hot streak vector.  What is interesting is that, intuitively, it complements hot streak by looking back into the an arbitrary horizon in the past and incorporates the X most recent games (ands pads with 0s if there are less than X games).  But rival streak goes beyond the current season and looks at the most recent $min(X, \text{number games played against rival team in history}$.  So when hot streak provides little to no information there is still a good chance that rival streak will have some data that the model can leverage (obviously there is nothing we can do for the birth range of the dataset).

As a test-bed we evaluated the impact of hot streak and rival streak in a single hidden layer network (the network model is in section~\ref{sec:architectures-winner-winning-team-id}).  The results are in tables~\ref{tbl:streak-impact-compact}~and~\ref{tbl:streak-impact-detailed} where the training data is evaluated on a batch of size 64.  Both tables seem to suggest that the addition of hot streak may not provide any additional information in predicting the outcome of a game as the accuracy slightly descreases in the compact dataset but slightly increases in the detailed dataset.  However, it is evident that rival streak is a good indicator of who will win.


\begin{tabular}{|l|c|c|}
\hline
Data & Training & Validation & Testing\\
\hline
Vanilla & 0.625 & 0.538 & 0.534\\
+hot streak & 0.500 & 0.474 & 0.520\\
+rival streak & 0.719 & 0.640 & 0.631\\
+both streaks & 0.625 & 0.621 & 0.657\\
\end{tabular}
\caption{Impact of the handcrafted streak features using the compact dataset.}
\label{tbl:streak-impact-detaled}


\begin{tabular}{|l|c|c|}
\hline
Data & Training & Validation & Testing\\
\hline
Vanilla & 0.641 & 0.537 & 0.534\\
+hot streak & 0.516 & 0.531 & 0.540\\
+rival streak & 0.594 & 0.576 & 0.589\\
+both streaks & 0.781 & 0.694 & 0.694\\
\end{tabular}
\caption{Impact of the handcrafted streak features using the detailed dataset.}
\label{tbl:streak-impact-detaled}



\section{Network Input Output Architectures}

The basic model consists of an input layer, one or more hidden layers, followed by an output layer.  We investigate three different input/output layer combinations and remark on the idea behind each one and its intuitive reasoning.


\subsection{Game Outcomes}
\label{sec:architectures-winner}

The input examples 

\subsubsection{Predicting Winning Team ID}
\label{sec:architectures-winner-winning-team-id}

This model asked to output the winning team's id given the input training examples.  For this, it should be expected to be given each team's id as part of the input and then output one of the team's id the model believe will win.  Recall that a team's id is given as a one-hot encoding, so if there are T teams then the vector for a team id will be a T-dimensional vector with a single 1 in one of the cells.

So, an example of a single input is:

% Math mode for matrix
\[
\begin{bmatrix}
  \begin{Bmatrix}
    \text{one hot encoding for team1's id}
  \end{Bmatrix}
  \\
  \begin{Bmatrix}
    \text{one hot encoding for team1's feature snapshot}
  \end{Bmatrix}
  \\
  \begin{Bmatrix}
    \text{one hot encoding for team2's id}
  \end{Bmatrix}
  \\
  \begin{Bmatrix}
    \text{vector for team2's feature snapshot}
  \end{Bmatrix}
  \begin{Bmatrix}
    \text{vector for rival streak wrt team1 (win means team1 won)}
  \end{Bmatrix}
\end{bmatrix}
\]

which will be \textit{flattened} into a single row vector in the input matrix.

And the output would be
\[
\begin{Bmatrix}
  \text{one hot encoding of winning team}
\end{Bmatrix}
\]


The advantages for this model is that we can read the winning team directly from the output layer and that, perhaps, the model can learn additional features between team-pairings.  For example, if team1 always beats team2 (according to historical data) then independent of how poorly team1 has done during the current season we may still choose to predict that team1 will win.  Though this should be something that the rival streak captures and the ability for the model to output a team that was not even playing the same is prone to more errors that a model that simply predicts a binary classification (team1 either wins or loses).  This additional burden on the model may require more data to simply learn valid outputs given the inputs.

\subsection{Predicting Top/Bottom Team}
\label{sec:architectures-winner-top-bottom}

This model is asked to output one of the following two vectors: $\begin{Bmatrix} 1, 0 \end{Bmatrix}$ or $\begin{Bmatrix} 0, 1 \end{Bmatrix}$ representing that either the first or second team will win, respectively.  For model, we no longer require the input to include either team's unqiue id as the output is relative to the ordering of the input.  The intuitive reasoning for this is that the team's themselves are probably not a significant indicator for winning or losing, but their seasonal and lifetimes statistics are more relevant.  This also removes the requirement for the model to learn that the output has a notion of validity according to the input.  Outputs that don't make sense are removed entirely with this model.  Furthermore, this reduces the memory burden during learning as we have a reduced feature size.  Since there are approximately 350 different teams, this reduces the feature dimension by $2 * 350 = 700$ (even though most of these features are 0).

So, an example of a single input is:

% Math mode for matrix
\[
\begin{bmatrix}
  \\
  \begin{Bmatrix}
    \text{vector for team1's feature snapshot}
  \end{Bmatrix}
  \\
  \begin{Bmatrix}
    \text{vector for team2's feature snapshot}
  \end{Bmatrix}
  \begin{Bmatrix}
    \text{vector for rival streak wrt team1 (win means team1 won)}
  \end{Bmatrix}
\end{bmatrix}
\]

which will be \textit{flattened} into a single row vector in the input matrix.

And the output would be
\[
\begin{cases}
  \begin{Bmatrix}
    1, 0
  \end{Bmatrix} & \text{ if the first input team is predicted to win}
  \begin{Bmatrix}
    0, 1
  \end{Bmatrix} & \text{ if the second input team is predicted to win}
\end{cases}
\]


The advantages for this model is that we can read the winning team directly from the output layer and that, perhaps, the model can learn additional features between team-pairings.  For example, if team1 always beats team2 (according to historical data) then independent of how poorly team1 has done during the current season we may still choose to predict that team1 will win.  Though this should be something that the rival streak captures and the ability for the model to output a team that was not even playing the same is prone to more errors that a model that simply predicts a binary classification (team1 either wins or loses).  This additional burden on the model may require more data to simply learn valid outputs given the inputs.


\subsubsection{Predicting Probabiliy Top Team Wins}
\label{sec:architectures-winner-top-team-probability}

This model is asked to output one of the the probability that the first input team beats the second. For the model, we no longer require the input to include either team's unqiue id as the output is relative to the ordering of the input.  The intuitive reasoning for this is that the team's themselves are probably not a significant indicator for winning or losing, but their seasonal and lifetimes statistics are more relevant.  This also removes the requirement for the model to learn that the output has a notion of validity according to the input.  Outputs that don't make sense are removed entirely with this model.  Furthermore, this reduces the memory burden during learning as we have a reduced feature size.  Since there are approximately 350 different teams, this reduces the feature dimension by $2 * 350 = 700$ (even though most of these features are 0).  The reason to try this model is that it outputs a single probabiliy instead of a probability distribution like in \ref{sec:architectures-winner-top-bottom}; however, similar results were expected.

So, an example of a single input is:

% Math mode for matrix
\[
\begin{bmatrix}
  \\
  \begin{Bmatrix}
    \text{vector for team1's feature snapshot}
  \end{Bmatrix}
  \\
  \begin{Bmatrix}
    \text{vector for team2's feature snapshot}
  \end{Bmatrix}
  \begin{Bmatrix}
    \text{vector for rival streak wrt team1 (win means team1 won)}
  \end{Bmatrix}
\end{bmatrix}
\]

which will be \textit{flattened} into a single row vector in the input matrix.

And the output would be
\[
\begin{cases}
  1 & \text{ if the first input team is predicted to win}
  \\
  0 & \text{ if the second input team is predicted to win}
\end{cases}
\]


The advantages for this model is that we can read the winning team directly from the output layer and that, perhaps, the model can learn additional features between team-pairings.  For example, if team1 always beats team2 (according to historical data) then independent of how poorly team1 has done during the current season we may still choose to predict that team1 will win.  Though this should be something that the rival streak captures and the ability for the model to output a team that was not even playing the same is prone to more errors that a model that simply predicts a binary classification (team1 either wins or loses).  This additional burden on the model may require more data to simply learn valid outputs given the inputs.




\section{Neural Network Architecture}
\label{sec:nn-architecture}


\section{Conclusion}
\label{sec:conclusion}


\small{
\nocite{*}
\bibliographystyle{plainnat}
\bibliography{research}
}
\end{document}
